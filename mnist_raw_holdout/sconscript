# MNIST
# Take in the raw image and use a CNN on top
# uniform acceptance is calculated by generating images by inverse PCA

import os

from os.path import join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption
import numpy as np

Import('env')
localenv = env.Clone()

nest = SConsWrap(Nest(), localenv['output'], alias_environment=localenv)

# First run `python process_mnist.py --out-train-data /fh/fast/matsen_e/jfeng2/mnist/mnist_train_raw.pkl --out-test-data /fh/fast/matsen_e/jfeng2/mnist/mnist_test_raw.pkl --out-weird /fh/fast/matsen_e/jfeng2/mnist/weird_mnist_test_raw.pkl`


TRAIN_DATA = "/fh/fast/matsen_e/jfeng2/mnist/mnist_train_raw.pkl"
TEST_DATA = "/fh/fast/matsen_e/jfeng2/mnist/mnist_test_raw.pkl"
# Weird data is fashion MNIST
WEIRD_DATA = "/fh/fast/matsen_e/jfeng2/mnist/weird_mnist_test_raw.pkl"
COST_DECLINES = [0.3]
NUM_ENSEMBLE = 5
LEARNING_RATE = 0.001
KFOLDS = 5
FOLD_IDXS = [0]
DO_NO_HARMS = [0.25]

config_dict = {
    "act_func": "relu",
    "parametric_form": "multinomial",
    "density_layer_sizes": "28~28~1+conv3~3~1~32:1~1~1~1+pool+conv3~3~32~32:1~2~2~1+pool",
    "density_weight": [0.0002],
    "decision_weight": [0.0002],
    "weight_penalty_type": "ridge",
    "inflation": [1],
    "log_barrier": [0.0001],
    "batch_size": 256,
    "support_sim_num": 256,
    # Corresponds to max epochs
    "max_iters": 30,
    "num_inits": 1,
    "alpha": 0.05,
}

nest.add(
    'cost_decline',
    COST_DECLINES,
    label_func=lambda c: 'cost_decline%s' % str(c),
)

nest.add_aggregate('aggregate_results', list)
nest.add(
    'seed',
    range(100,120),
    label_func=lambda c: 'model_seed%d' % c,
)

nest.add_aggregate('aggregate_ensemble_nns', list)
nest.add_aggregate('aggregate_ensemble_ulm_nns', list)
nest.add_aggregate('aggregate_borrow_only', list)

nest.add(
    'fold_idx',
    FOLD_IDXS,
    label_func=lambda c: 'fold_idx%d' % c,
)

@nest.add_target_with_env(localenv)
def split_data(env, outdir, c):
    targets = [
        join(outdir, 'obs_data_split.pkl')]
    cmd = [
        'python create_data_split.py',
        '--seed',
        c['seed'],
        '--k-fold',
        KFOLDS,
        '--fold-idx',
        c['fold_idx'],
        '--in-data-file',
        TRAIN_DATA,
        '--out-file ${TARGETS[0]}']
    return env.Command(
        targets,
        [],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_ensemble_nns(env, outdir, c):
    targets = [
        join(outdir, 'fit_nn.pkl'),
        join(outdir, 'fit_nn_log.txt')]
    cmd = [
        'python fit_density_nn.py',
        '--seed',
        50 + int(c['fold_idx'] * 40),
        '--data-file',
        TRAIN_DATA,
        '--data-split-file ${SOURCES[0]}',
        '--density-parametric-form',
        config_dict["parametric_form"],
        '--density-layer-sizes',
        config_dict["density_layer_sizes"],
        '--density-weight',
        ",".join(map(str, config_dict["density_weight"])),
        '--weight-penalty-type',
        config_dict['weight_penalty_type'],
        '--act-func',
        config_dict['act_func'],
        '--dropout 0',
        '--cv 3',
        '--num-ensemble',
        NUM_ENSEMBLE,
        '--num-init',
        config_dict['num_inits'],
        '--max-iter',
        config_dict['max_iters'],
        '--learning-rate',
	LEARNING_RATE,
        '--batch-size',
        config_dict['batch_size'],
        '--do-distributed',
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_ensemble_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_borrow_only_ensemble_ulm(env, outdir, c):
    targets = [
        join(outdir, 'fit_borrow_only_ensemble_ulm.pkl'),
        join(outdir, 'fit_borrow_only_ensemble_ulm_log.txt')]
    cmd = [
        'python fit_simultaneous_decision_density_nn.py',
        '--seed',
        10 + int(c['fold_idx'] * 4) + int(c['cost_decline'] * 100),
        '--data-file',
        TRAIN_DATA,
        '--data-split-file ${SOURCES[0]}',
        '--density-parametric-form',
        config_dict["parametric_form"],
        '--density-layer-sizes',
        config_dict["density_layer_sizes"],
        '--density-weight-param',
        ",".join(map(str, config_dict["density_weight"])),
        '--decision-weight-param',
        ",".join(map(str, config_dict["decision_weight"])),
        '--log-barrier',
        ",".join(map(str, config_dict["log_barrier"])),
        '--weight-penalty-type',
        config_dict["weight_penalty_type"],
        '--inflation 1',
        '--do-no-harm 0',
        '--cost-decline',
        c['cost_decline'],
        '--num-ensemble',
        NUM_ENSEMBLE,
        '--do-distributed',
        '--act-func',
        config_dict['act_func'],
        '--cv 3',
        '--num-init',
        config_dict['num_inits'],
        '--support-sim-num 1',
        '--max-iter',
        config_dict['max_iters'],
        '--learning-rate',
        LEARNING_RATE,
        '--batch-size',
        config_dict['batch_size'],
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_borrow_only'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'],
        ' '.join(map(str, cmd)))

nest.add(
    'do_no_harm',
    DO_NO_HARMS,
    label_func=lambda c: 'do_no_harm%s' % str(c),
)

@nest.add_target_with_env(localenv)
def fit_ensemble_ulm(env, outdir, c):
    targets = [
        join(outdir, 'fit_ensemble_ulm.pkl'),
        join(outdir, 'fit_ensemble_ulm_log.txt')]
    cmd = [
        'python fit_simultaneous_decision_density_nn.py',
        '--seed',
        10 + int(c['fold_idx'] * 4) + int(c['cost_decline'] * 100),
        '--data-file',
        TRAIN_DATA,
        '--data-split-file ${SOURCES[0]}',
        '--density-parametric-form',
        config_dict["parametric_form"],
        '--density-layer-sizes',
        config_dict["density_layer_sizes"],
        '--density-weight-param',
        ",".join(map(str, config_dict["density_weight"])),
        '--decision-weight-param',
        ",".join(map(str, config_dict["decision_weight"])),
        '--log-barrier',
        ",".join(map(str, config_dict["log_barrier"])),
        '--weight-penalty-type',
        config_dict["weight_penalty_type"],
        '--inflation',
        ",".join(map(str, config_dict['inflation'])),
        '--do-no-harm',
        c['do_no_harm'],
        '--cost-decline',
        c['cost_decline'],
        '--num-ensemble',
        NUM_ENSEMBLE,
        '--do-distributed',
        '--act-func',
        config_dict['act_func'],
        '--cv 3',
        '--num-init',
        config_dict['num_inits'],
        '--support-sim-num',
        config_dict['support_sim_num'],
        '--max-iter',
        config_dict['max_iters'],
        '--learning-rate',
        LEARNING_RATE,
        '--batch-size',
        config_dict['batch_size'],
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_ensemble_ulm_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'],
        ' '.join(map(str, cmd)))


nest.pop('do_no_harm')
nest.pop('fold_idx')

@nest.add_target_with_env(localenv)
def plot(env, outdir, c):
    targets = [
        join(outdir, 'plot_log.txt'),
        join(outdir, 'results.pkl'),
        join(outdir, 'example_images.pdf')]
    sources = [
        c['aggregate_ensemble_ulm_nns'],
        c['aggregate_ensemble_nns'],
        c['aggregate_borrow_only'],
    ]
    start_idx = 0
    result_file_names = []
    for model_res in sources:
        num_to_agg = len(model_res)
        result_file_names.append(
            ",".join(["${SOURCES[%d]}" % i for i in range(start_idx, start_idx + num_to_agg)]))
        start_idx += num_to_agg
    cmd = [
        'python plot_mnist_holdout.py',
        '--ensemble-eps 0.005',
        '--cost-decline',
        c['cost_decline'],
        '--train-data-file',
        TRAIN_DATA,
        '--test-data-file',
        TEST_DATA,
        '--weird-data-file',
        WEIRD_DATA,
        '--ensemble-ulm-files',
        result_file_names[0],
        '--ensemble-files',
        result_file_names[1],
        '--ensemble-borrow-files',
        result_file_names[2],
        '--log-file ${TARGETS[0]}',
        '--out-results ${TARGETS[1]}',
        '--out-examples ${TARGETS[2]}',
    ]
    c['aggregate_results'].append(targets[1])
    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd)))

nest.pop('seed')

@nest.add_target_with_env(localenv)
def aggregate(env, outdir, c):
    targets = [
        join(outdir, 'plot_log_new.txt')]
    sources = [
        c['aggregate_results'],
    ]
    start_idx = 0
    result_file_names = []
    for model_res in sources:
        num_to_agg = len(model_res)
        result_file_names.append(
            ",".join(["${SOURCES[%d]}" % i for i in range(start_idx, start_idx + num_to_agg)]))
        start_idx += num_to_agg
    cmd = [
        'python plot_aggregate_results.py',
        '--result-files',
        result_file_names[0],
        '--log-file ${TARGETS[0]}',
    ]
    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd)))
