# Tests the experiment where we hold out an age group
# and compare performance on the in-sample and out-of-sample age groups
# Predicting length of stay

import os

from os.path import join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption
import numpy as np

Import('env')
localenv = env.Clone()

nest = SConsWrap(Nest(), localenv['output'], alias_environment=localenv)

KFOLDS = 3
FOLD_IDXS = [0]
LEARNING_RATE = 0.0005
COST_DECLINES = [0.25]

config_dict = {
    "act_func": "relu",
    "interval_layer_sizes": "%d+20+10",
    "interval_weight": [0.001],
    "decision_weight": [0.00001],
    "log_barrier": [0.0001],
    "weight_penalty_type": "ridge",
    "do_no_harm": [100],
    "inflation": [1],
    "support_sim_num": 2000,
    "max_iters": 2000,
    "num_inits": 1,
    "alpha": 0.2,
}

nest.add(
    'holdout_age',
    [
         (0,50) # holdout people 0-50 years for testing. train on 50+
    ],
    label_func=lambda c: 'age_holdout_%d_%d' % c,
)
nest.add(
    'num_p',
    [122],
    label_func=lambda c: 'num_p_%d' % c,
)
@nest.add_target_with_env(localenv)
def data_create(env, outdir, c):
    targets = [
        join(outdir, 'train_data.pkl'),
        join(outdir, 'test_data.pkl'),
        join(outdir, 'age_data.pkl'),
    ]
    cmd = [
        'python process_mimic_holdout_pca.py',
        '--holdout-age',
        '--holdout-max-age',
        c['holdout_age'][1],
        '--holdout-min-age',
        c['holdout_age'][0],
        '--num-pca',
        c['num_p'] - 2,
        '--in-train-data ../data/mimic/length-of-stay/mimic_los_train.pkl --in-test-data ../data/mimic/length-of-stay/mimic_los_test.pkl',
        '--out-train ${TARGETS[0]}',
        '--out-test ${TARGETS[1]}',
        '--out-age ${TARGETS[2]}']
    return env.Command(
        targets,
        [],
        ' '.join(map(str, cmd)))

nest.add(
    'cost_decline',
    COST_DECLINES,
    label_func=lambda c: 'cost_decline%s' % str(c),
)

nest.add_aggregate('aggregate_results', list)

nest.add(
    'seed',
    range(90, 110),
    label_func=lambda c: 'seed%d' % c,
)
nest.add_aggregate('aggregate_nns', list)
nest.add_aggregate('aggregate_ulm_nns', list)
nest.add_aggregate('aggregate_borrow_only_nns', list)

nest.add(
    'fold_idx',
    FOLD_IDXS,
    label_func=lambda c: 'fold_idx%d' % c,
)

@nest.add_target_with_env(localenv)
def split_data(env, outdir, c):
    targets = [
        join(outdir, 'obs_data_split.pkl')]
    cmd = [
        'python create_data_split.py',
        '--seed',
        c['seed'],
        '--k-fold',
        KFOLDS,
        '--fold-idx',
        c['fold_idx'],
        '--in-data-file ${SOURCES[0]}',
        '--out-file ${TARGETS[0]}']
    return env.Command(
        targets,
        c['data_create'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_plain_nns(env, outdir, c):
    targets = [
        join(outdir, 'fit_plain.pkl'),
        join(outdir, 'fit_plain_log.txt')]
    cmd = [
        'srun --cpus-per-task 4',
        'python fit_interval_nn.py',
        '--seed',
        12 + int(c['fold_idx'] * 40) + c['seed'],
        '--data-file ${SOURCES[1]}',
        '--data-split-file ${SOURCES[0]}',
        '--interval-alpha',
        config_dict["alpha"],
        '--interval-layer-sizes',
        config_dict["interval_layer_sizes"] % c['num_p'],
        '--interval-weight',
        ",".join(map(str, config_dict["interval_weight"])),
        '--weight-penalty ridge',
        '--act-func',
        config_dict['act_func'],
        '--cv 3',
        '--dropout 0',
        '--num-init',
        config_dict['num_inits'],
        '--max-iter',
        config_dict['max_iters'],
        '--learning-rate',
	LEARNING_RATE,
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'] + c['data_create'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_borrow_only_nns(env, outdir, c):
    targets = [
        join(outdir, 'fit_borrow_only_nn.pkl'),
        join(outdir, 'fit_borrow_only_nn_log.txt')]
    cmd = [
        'srun --cpus-per-task 4',
        'python fit_simultaneous_decision_interval_nn.py',
        '--seed',
        10 + int(c['fold_idx'] * 4) + c['seed'],
        '--data-file ${SOURCES[1]}',
        '--data-split-file ${SOURCES[0]}',
        '--interval-alpha',
        config_dict["alpha"],
        '--interval-layer-sizes',
        config_dict["interval_layer_sizes"] % c['num_p'],
        '--interval-weight-param',
        ",".join(map(str, config_dict["interval_weight"])),
        '--decision-weight-param',
        ",".join(map(str, config_dict["decision_weight"])),
        '--log-barrier',
        ",".join(map(str, config_dict["log_barrier"])),
        '--weight-penalty-type',
        config_dict["weight_penalty_type"],
        '--do-no-harm 0',
        '--inflation',
        ",".join(map(str, config_dict["inflation"])),
        '--cost-decline',
        c['cost_decline'],
        '--act-func',
        config_dict['act_func'],
        '--cv 3',
        '--num-init',
        config_dict['num_inits'],
        '--support-sim-num 1',
        '--batch-size 2100',
        '--max-iter',
        config_dict['max_iters'],
        '--learning-rate',
        LEARNING_RATE,
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_borrow_only_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'] + c['data_create'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_ulm_nns(env, outdir, c):
    targets = [
        join(outdir, 'fit_ulm_nn_with_dec.pkl'),
        join(outdir, 'fit_ulm_nn_log_with_dec.txt')]
    cmd = [
        'srun --cpus-per-task 4',
        'python fit_simultaneous_decision_interval_nn.py',
        '--seed',
        10 + int(c['fold_idx'] * 4) + c['seed'],
        '--data-file ${SOURCES[1]}',
        '--data-split-file ${SOURCES[0]}',
        '--interval-alpha',
        config_dict["alpha"],
        '--interval-layer-sizes',
        config_dict["interval_layer_sizes"] % c['num_p'],
        '--interval-weight-param',
        ",".join(map(str, config_dict["interval_weight"])),
        '--decision-weight-param',
        ",".join(map(str, config_dict["decision_weight"])),
        '--log-barrier',
        ",".join(map(str, config_dict["log_barrier"])),
        '--weight-penalty-type',
        config_dict["weight_penalty_type"],
        '--do-no-harm',
        ",".join(map(str, config_dict["do_no_harm"])),
        '--inflation',
        ",".join(map(str, config_dict["inflation"])),
        '--cost-decline',
        c['cost_decline'],
        '--act-func',
        config_dict['act_func'],
        '--cv 3',
        '--num-init',
        config_dict['num_inits'],
        '--support-sim-num',
        config_dict['support_sim_num'],
        '--batch-size 2100',
        '--max-iter',
        config_dict['max_iters'],
        '--learning-rate',
        LEARNING_RATE,
        '--fitted-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}']
    c['aggregate_ulm_nns'].append(targets[0])
    return env.Command(
        targets,
        c['split_data'] + c['data_create'],
        ' '.join(map(str, cmd)))

nest.pop('fold_idx')

@nest.add_target_with_env(localenv)
def plot(env, outdir, c):
    targets = [
        join(outdir, 'plot_log.txt'),
        join(outdir, 'results.pkl')]
    sources = [
        c['data_create'][:2],
        c['aggregate_ulm_nns'],
        c['aggregate_borrow_only_nns'],
        c['aggregate_nns'],
    ]
    start_idx = 2
    result_file_names = []
    for model_res in sources[1:]:
        num_to_agg = len(model_res)
        result_file_names.append(
            ",".join(["${SOURCES[%d]}" % i for i in range(start_idx, start_idx + num_to_agg)]))
        start_idx += num_to_agg
    cmd = [
        'python plot_mimic_holdout.py',
        '--eps 0.1',
        '--threshold-adjust 0',
        '--cost-decline',
        c['cost_decline'],
        '--train-data-file ${SOURCES[0]}',
        '--test-data-file ${SOURCES[1]}',
        '--ulm-files',
        result_file_names[0],
        '--borrow-only-files',
        result_file_names[1],
        '--plain-files',
        result_file_names[2],
        '--log-file ${TARGETS[0]}',
        '--out-results ${TARGETS[1]}',
    ]
    c['aggregate_results'].append(targets[1])
    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd)))

nest.pop('seed')

@nest.add_target_with_env(localenv)
def aggregate(env, outdir, c):
    targets = [
        join(outdir, 'plot_log_new.txt')]
    sources = [
        c['aggregate_results'],
    ]
    start_idx = 0
    result_file_names = []
    for model_res in sources:
        num_to_agg = len(model_res)
        result_file_names.append(
            ",".join(["${SOURCES[%d]}" % i for i in range(start_idx, start_idx + num_to_agg)]))
        start_idx += num_to_agg
    cmd = [
        'python plot_mimic_aggregate_results.py',
        '--result-files',
        result_file_names[0],
        '--log-file ${TARGETS[0]}',
    ]
    return env.Command(
        targets,
        sources,
        ' '.join(map(str, cmd)))
